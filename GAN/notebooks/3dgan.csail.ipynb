{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e11d8ee",
   "metadata": {},
   "source": [
    "# Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f34a9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.9.0\n",
      "\n",
      "torch     : 2.0.0.dev20230208\n",
      "wandb     : 0.13.10\n",
      "matplotlib: 3.6.3\n",
      "seaborn   : 0.12.2\n",
      "numpy     : 1.24.1\n",
      "pylab     : unknown\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
    "rcParams[\"figure.figsize\"] = 16,10\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "from typing import Optional, List, Tuple, Dict\n",
    "from torchsummary import summary\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -p torch,wandb,matplotlib,seaborn,numpy,pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7710a44",
   "metadata": {},
   "source": [
    "## Network Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c38ae",
   "metadata": {},
   "source": [
    "### Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96122b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE3DGAN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int = 3, \n",
    "        channels: List[int] = [64, 128, 256, 512, 400],\n",
    "        kernel_sizes: List[int] = [11, 5, 5, 5, 8],\n",
    "        strides: List[int] = [4, 2, 2, 2, 1]\n",
    "    ) -> None:\n",
    "        super(VAE3DGAN, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        layers = []\n",
    "        \n",
    "        for ix in range(len(channels)):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=in_channels, \n",
    "                        out_channels=channels[ix],\n",
    "                        kernel_size=kernel_sizes[ix], \n",
    "                        stride=strides[ix], \n",
    "                        padding=1\n",
    "                    ), \n",
    "                    nn.BatchNorm2d(channels[ix]),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "            in_channels = channels[ix]\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def sample_normal(self, std: torch.Tensor) -> torch.Tensor:\n",
    "        sampler = torch.distributions.Normal(loc=0, scale=1)\n",
    "        return sampler.sample(std.shape)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        latent = self.net(x)\n",
    "        mu, std = latent[:, :200,], latent[:, 200:]\n",
    "        z = self.sample_normal(std)\n",
    "        latent = mu + z * std\n",
    "        return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64674bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE3DGAN(\n",
       "  (net): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(512, 400, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE3DGAN()\n",
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c55bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 62, 62]          23,296\n",
      "       BatchNorm2d-2           [-1, 64, 62, 62]             128\n",
      "              ReLU-3           [-1, 64, 62, 62]               0\n",
      "            Conv2d-4          [-1, 128, 30, 30]         204,928\n",
      "       BatchNorm2d-5          [-1, 128, 30, 30]             256\n",
      "              ReLU-6          [-1, 128, 30, 30]               0\n",
      "            Conv2d-7          [-1, 256, 14, 14]         819,456\n",
      "       BatchNorm2d-8          [-1, 256, 14, 14]             512\n",
      "              ReLU-9          [-1, 256, 14, 14]               0\n",
      "           Conv2d-10            [-1, 512, 6, 6]       3,277,312\n",
      "      BatchNorm2d-11            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-12            [-1, 512, 6, 6]               0\n",
      "           Conv2d-13            [-1, 400, 1, 1]      13,107,600\n",
      "      BatchNorm2d-14            [-1, 400, 1, 1]             800\n",
      "             ReLU-15            [-1, 400, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 17,435,312\n",
      "Trainable params: 17,435,312\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 9.85\n",
      "Params size (MB): 66.51\n",
      "Estimated Total Size (MB): 77.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vae, input_size=(3, 256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df859812",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd14372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int = 200,\n",
    "        channels: List[int] = [512, 256, 128, 64, 1],\n",
    "        kernel_sizes: List[int] = [4, 4, 4, 4, 4],\n",
    "        strides: List[int] = [1, 2, 2, 2, 2], \n",
    "        paddings: List[int] = [0, 1, 1, 1, 1]\n",
    "    ) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        for ix in range(len(channels)):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose3d(\n",
    "                        in_channels=in_channels, \n",
    "                        out_channels=channels[ix],\n",
    "                        stride=strides[ix],\n",
    "                        kernel_size=kernel_sizes[ix], \n",
    "                        padding=paddings[ix]\n",
    "                    ), \n",
    "                    nn.BatchNorm3d(channels[ix]), \n",
    "                    nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "            in_channels = channels[ix]\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce707cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (net): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose3d(200, 512, kernel_size=(4, 4, 4), stride=(1, 1, 1))\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose3d(512, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose3d(256, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConvTranspose3d(128, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): ConvTranspose3d(64, 1, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = Generator()\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba9bea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose3d-1         [-1, 512, 4, 4, 4]       6,554,112\n",
      "       BatchNorm3d-2         [-1, 512, 4, 4, 4]           1,024\n",
      "              ReLU-3         [-1, 512, 4, 4, 4]               0\n",
      "   ConvTranspose3d-4         [-1, 256, 8, 8, 8]       8,388,864\n",
      "       BatchNorm3d-5         [-1, 256, 8, 8, 8]             512\n",
      "              ReLU-6         [-1, 256, 8, 8, 8]               0\n",
      "   ConvTranspose3d-7      [-1, 128, 16, 16, 16]       2,097,280\n",
      "       BatchNorm3d-8      [-1, 128, 16, 16, 16]             256\n",
      "              ReLU-9      [-1, 128, 16, 16, 16]               0\n",
      "  ConvTranspose3d-10       [-1, 64, 32, 32, 32]         524,352\n",
      "      BatchNorm3d-11       [-1, 64, 32, 32, 32]             128\n",
      "             ReLU-12       [-1, 64, 32, 32, 32]               0\n",
      "  ConvTranspose3d-13        [-1, 1, 64, 64, 64]           4,097\n",
      "      BatchNorm3d-14        [-1, 1, 64, 64, 64]               2\n",
      "             ReLU-15        [-1, 1, 64, 64, 64]               0\n",
      "          Sigmoid-16        [-1, 1, 64, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 17,570,627\n",
      "Trainable params: 17,570,627\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 71.75\n",
      "Params size (MB): 67.03\n",
      "Estimated Total Size (MB): 138.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(gen, input_size=(200, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4dcaa",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51245e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 1, \n",
    "        channels: List[int] = [64, 128, 256, 512, 1],\n",
    "        kernel_sizes: List[int] = [4, 4, 4, 4, 4],\n",
    "        strides: List[int] = [4, 2, 2, 2, 1],\n",
    "    ) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        for ix in range(len(channels)):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv3d(\n",
    "                        in_channels=in_channels, \n",
    "                        out_channels=channels[ix], \n",
    "                        kernel_size=kernel_sizes[ix],\n",
    "                        stride=strides[ix], \n",
    "                        padding=1\n",
    "                    ), \n",
    "                    nn.BatchNorm3d(channels[ix]),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                )\n",
    "            )\n",
    "            in_channels = channels[ix]\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c03857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv3d(1, 64, kernel_size=(4, 4, 4), stride=(4, 4, 4), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv3d(64, 128, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(128, 256, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv3d(256, 512, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv3d(512, 1, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = Discriminator()\n",
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08837167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1       [-1, 64, 16, 16, 16]           4,160\n",
      "       BatchNorm3d-2       [-1, 64, 16, 16, 16]             128\n",
      "         LeakyReLU-3       [-1, 64, 16, 16, 16]               0\n",
      "            Conv3d-4         [-1, 128, 8, 8, 8]         524,416\n",
      "       BatchNorm3d-5         [-1, 128, 8, 8, 8]             256\n",
      "         LeakyReLU-6         [-1, 128, 8, 8, 8]               0\n",
      "            Conv3d-7         [-1, 256, 4, 4, 4]       2,097,408\n",
      "       BatchNorm3d-8         [-1, 256, 4, 4, 4]             512\n",
      "         LeakyReLU-9         [-1, 256, 4, 4, 4]               0\n",
      "           Conv3d-10         [-1, 512, 2, 2, 2]       8,389,120\n",
      "      BatchNorm3d-11         [-1, 512, 2, 2, 2]           1,024\n",
      "        LeakyReLU-12         [-1, 512, 2, 2, 2]               0\n",
      "           Conv3d-13           [-1, 1, 1, 1, 1]          32,769\n",
      "      BatchNorm3d-14           [-1, 1, 1, 1, 1]               2\n",
      "        LeakyReLU-15           [-1, 1, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,049,795\n",
      "Trainable params: 11,049,795\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.00\n",
      "Forward/backward pass size (MB): 7.97\n",
      "Params size (MB): 42.15\n",
      "Estimated Total Size (MB): 51.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(disc, input_size=(1, 64, 64, 64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
