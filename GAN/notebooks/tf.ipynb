{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d2b909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 216 µs (started: 2023-03-08 18:56:18 +05:30)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2739ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.9.0\n",
      "\n",
      "tensorflow       : 2.10.0\n",
      "tensorflow_addons: 0.19.0\n",
      "pandas           : 1.5.3\n",
      "\n",
      "time: 3.94 s (started: 2023-03-08 18:56:18 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import wandb\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -p tensorflow,tensorflow_addons,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b8ee1",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a818da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.25 ms (started: 2023-03-08 18:56:22 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class Conv2dBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters: int, kernel_size: int, strides: int, padding: str, name: str) -> None:\n",
    "        super(Conv2dBlock, self).__init__()\n",
    "        self.conv = keras.layers.Conv2D(\n",
    "            filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, name=f'{name}_conv'\n",
    "        )\n",
    "        self.bn = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.conv(x)\n",
    "        reshape = False\n",
    "        if len(x.shape) == 5:\n",
    "            shape = x.shape\n",
    "            reshape = True\n",
    "            x = tf.reshape(x, [shape[0], shape[1], shape[2], -1])\n",
    "            \n",
    "        if reshape:\n",
    "            x = tf.reshape(x, shape=shape)\n",
    "        x = self.bn(x)\n",
    "        x = keras.activations.relu(x)\n",
    "        return x\n",
    "    \n",
    "class Conv2dTransposeBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters: int, kernel_size: int, strides: int, padding: str, name: str) -> None:\n",
    "        super(Conv2dTransposeBlock, self).__init__()\n",
    "        self.conv = keras.layers.Conv2DTranspose(\n",
    "            filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, name=f'{name}_conv'\n",
    "        )\n",
    "        self.bn = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.conv(x)\n",
    "        reshape = False\n",
    "        if len(x.shape) == 5:\n",
    "            shape = x.shape\n",
    "            reshape = True\n",
    "            x = tf.reshape(x, [shape[0], shape[1], shape[2], -1])\n",
    "            \n",
    "        if reshape:\n",
    "            x = tf.reshape(x, shape=shape)\n",
    "        x = self.bn(x)\n",
    "        x = keras.activations.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97e5fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.17 ms (started: 2023-03-08 18:56:25 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class Conv3dBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters: int, kernel_size: int, strides: int, padding: str, name: str) -> None:\n",
    "        super(Conv3dBlock, self).__init__()\n",
    "        self.conv = keras.layers.Conv3D(\n",
    "            filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, name=f'{name}_conv'\n",
    "        )\n",
    "        self.bn = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.conv(x)\n",
    "        reshape = False\n",
    "        if len(x.shape) == 5:\n",
    "            shape = x.shape\n",
    "            reshape = True\n",
    "            x = tf.reshape(x, [shape[0], shape[1], shape[2], -1])\n",
    "        x = self.bn(x)\n",
    "        if reshape:\n",
    "            x = tf.reshape(x, shape=shape)\n",
    "        x = keras.activations.relu(x)\n",
    "        return x\n",
    "\n",
    "class Conv3dTransposeBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters: int, kernel_size: int, strides: int, padding: str, name: str) -> None:\n",
    "        super(Conv3dTransposeBlock, self).__init__()\n",
    "        self.conv = keras.layers.Conv3DTranspose(\n",
    "            filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, name=f'{name}_conv'\n",
    "        )\n",
    "        self.bn = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.conv(x)\n",
    "        reshape = False\n",
    "        if len(x.shape) == 5:\n",
    "            shape = x.shape\n",
    "            reshape = True\n",
    "            x = tf.reshape(x, [shape[0], shape[1], shape[2], -1])\n",
    "        x = self.bn(x)\n",
    "        if reshape:\n",
    "            x = tf.reshape(x, shape=shape)\n",
    "        x = keras.activations.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1806c3",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e24a292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.98 ms (started: 2023-03-08 18:56:27 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class ImageEncoder(keras.Model):\n",
    "    def __init__(self, filters: List[int] = [64, 128, 256, 512, 400], \n",
    "                 kernel_sizes: List[int] = [11, 5, 5, 5, 8], \n",
    "                 strides: List[int] = [4, 2, 2, 2, 1], \n",
    "                 padding: List[str] = ['same', 'same', 'same', 'same', 'valid']) -> None:\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self._layers = []\n",
    "        \n",
    "        for ix in range(len(filters)):\n",
    "            self._layers.append(\n",
    "                Conv2dBlock(\n",
    "                    filters=filters[ix], kernel_size=kernel_sizes[ix], strides=strides[ix], \n",
    "                    padding=padding[ix], name=f'img_enc_conv2d_{ix}'\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        self.encoder = keras.Sequential(layers=self._layers, name='image_encoder')\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        latent = self.encoder(x, training)\n",
    "        mu, std = latent[..., :200], latent[..., 200:]\n",
    "        latent = mu + std * tf.random.normal(std.shape)\n",
    "        return latent, mu, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d86e47",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e229b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.38 ms (started: 2023-03-08 18:56:29 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class Generator(keras.Model):\n",
    "    def __init__(self, filters: List[int] = [512, 256, 128, 64, 1], \n",
    "                 kernel_sizes: List[int] = [4, 4, 4, 4, 4], \n",
    "                 padding: List[str] = ['valid', 'same', 'same', 'same', 'same'],\n",
    "                 strides: List[int] = [1, 2, 2, 2, 2]) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        for ix in range(len(filters)):\n",
    "            layers.append(\n",
    "                Conv3dTransposeBlock(filters=filters[ix], kernel_size=kernel_sizes[ix], \n",
    "                                           strides=strides[ix], padding=padding[ix], name=f'gen_conv3d_{ix}')\n",
    "            )\n",
    "        \n",
    "        self.gen = keras.Sequential(layers=layers, name='generator')\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        return keras.activations.sigmoid(self.gen(tf.expand_dims(x, 1), training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24beff8e",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f7e15b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.73 ms (started: 2023-03-08 18:56:30 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(keras.Model):\n",
    "    def __init__(self, filters: List[int] = [64, 128, 256, 512, 1], \n",
    "                 kernel_sizes: List[int] = [4, 4, 4, 4, 4], \n",
    "                 padding: List[str] = ['same', 'same', 'same', 'same', 'valid'],\n",
    "                 strides: List[int] = [2, 2, 2, 2, 1]) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        layers = []\n",
    "        for ix in range(len(filters)):\n",
    "            layers.append(\n",
    "                Conv3dBlock(\n",
    "                    filters=filters[ix], kernel_size=kernel_sizes[ix], strides=strides[ix], \n",
    "                    padding=padding[ix], name=f'disc_conv3d_{ix}'\n",
    "                )\n",
    "            )\n",
    "        self.disc = keras.Sequential(layers=layers, name='discriminator')\n",
    "        \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.disc(x, training)\n",
    "        return keras.activations.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf1545",
   "metadata": {},
   "source": [
    "# Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c040ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Output shapes:-\n",
      "* x              : (32, 256, 256, 3)\n",
      "* latent         : (32, 1, 1, 200)\n",
      "* mu             : (32, 1, 1, 200)\n",
      "* std            : (32, 1, 1, 200)\n",
      "* reconstruction : (32, 64, 64, 64, 1)\n",
      "* disc_output    : (32, 1, 1, 1, 1)\n",
      "time: 9.78 s (started: 2023-03-08 18:56:31 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def run_test():\n",
    "    x = tf.random.normal((32, 256, 256, 3))\n",
    "    encoder = ImageEncoder()\n",
    "    decoder = Generator()\n",
    "    disc    = Discriminator()\n",
    "    \n",
    "    latent, mu, std = encoder(x)\n",
    "    reconstruction  = decoder(latent)\n",
    "    disc_output     = disc(reconstruction)\n",
    "    \n",
    "    print(f'''Output shapes:-\n",
    "* x              : {x.shape}\n",
    "* latent         : {latent.shape}\n",
    "* mu             : {mu.shape}\n",
    "* std            : {std.shape}\n",
    "* reconstruction : {reconstruction.shape}\n",
    "* disc_output    : {disc_output.shape}''')\n",
    "    \n",
    "run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67654c9",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b65b53d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 149 µs (started: 2023-03-08 18:56:41 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b929566",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Let $\\{x_i,y_i\\}$ be the training pairs, where $y_i$ is a 2D image and $x_i$ is the corresponding 3D shape. In each iteration $t$ of training, we first generate a random sample $z_t$ from $\\mathcal{N}(0, I)$. Then we update the discriminator $D$, the image encoder $E$, and the generator $G$ sequentially. Specifically, \n",
    "- __Step 1__: Update the disciminator $D$ by minimizing the following loss function: $$\\log(D(x_i)) + \\log(1 - D(G(z_t)))$$\n",
    "- __Step 2__: Update the image encoder $E$ by minimizing the following loss function: $$D_{KL}(\\mathcal{N}(E_{\\text{mean}}(y_i), E_{\\text{var}}(y_i))\\|\\mathcal{N(0, 1)})+\\|G(E(y_i)) - x_i\\|_2, $$ where $E_{\\text{mean}}(y_i)$ and $E_{\\text{var}}(y_i)$ are the predicted mean and variance of the latent variable $z$, respectively.\n",
    "- __Step 3__: Update the generator $G$ by minimizing the following loss function:\n",
    "$$\\log(1-D(G(z_t)))+\\|G(E(y_i)) - x_i\\|_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c52c86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.8 ms (started: 2023-03-08 19:34:50 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def run_training(num_epochs: int, train_ds: tf.data, valid_ds: tf.data, latent_dim: int):\n",
    "    encoder = ImageEncoder()\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "    \n",
    "    enc_optimizer = keras.optimizers.Adam(learning_rate=0.0025, beta_1=0.5, beta_2=0.5)\n",
    "    gen_optimizer = keras.optimizers.Adam(learning_rate=0.0025, beta_1=0.5, beta_2=0.5)\n",
    "    disc_optimizer = keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.5, beta_2=0.5)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        pbar = tqdm(enumerate(train_ds), total=len(train_ds), desc=f'EPOCH [{epoch+1}/{num_epochs}] (train) ')\n",
    "        for step, (y, x) in pbar:\n",
    "            '''\n",
    "            y - 2d image\n",
    "            x - 3d image\n",
    "            '''\n",
    "            batch_size = y.shape[0]\n",
    "            z = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "            \n",
    "            # Gradient Descent on Image Encoder\n",
    "            with tf.GradientTape() as tape:\n",
    "                latent, mu, logvar = encoder(y)\n",
    "                reconstructed = generator(latent)\n",
    "                \n",
    "                encoder_loss = -0.5 * (1 + logvar - tf.square(mu) - tf.exp(logvar))\n",
    "                encoder_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "                encoder_loss += tf.keras.losses.mse(y_pred=reconstructed, y_true=x)\n",
    "            grads = tape.gradient(encoder_loss, encoder.trainable_weights)\n",
    "            enc_optimizer.apply_gradients(zip(grads, encoder.trainable_weights))\n",
    "            \n",
    "            # Gradient Descent on Generator\n",
    "            with tf.GradientTape() as tape:\n",
    "                latent, mu, logvar = encoder(y)\n",
    "                reconstructed = generator(latent)    \n",
    "                generator_loss = keras.losses.binary_crossentropy(y_true=tf.ones_like(reconstructed), y_pred=reconstructed)\n",
    "                generator_loss += keras.losses.mse()\n",
    "            grads = tape.gradient(generator_loss, generator.trainable_weights)\n",
    "            gen_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "            \n",
    "            # Gradient Descent on Discriminator\n",
    "            with tf.GradientTape() as tape:\n",
    "                latent, mu, logvar = encoder(y)\n",
    "                reconstructed = generator(latent)\n",
    "                \n",
    "                disc_fake = discriminator(reconstructed)\n",
    "                disc_true = discriminator(tf.expand_dims(x, -1))\n",
    "                \n",
    "                discriminator_loss = keras.losses.binary_crossentropy(y_true=tf.ones_like(disc_true), y_pred=disc_true)\n",
    "                discriminator_loss += keras.losses.binary_crossentropy(y_true=tf.zeros_like(disc_fake), y_pred=disc_fake)\n",
    "            \n",
    "            accuracy = tf.reduce_sum((disc_fake > 0.5) == tf.zeros_like(disc_fake)) + tf.reduce_sum((disc_true > 0.5) == tf.ones_like(disc_true))\n",
    "            accuracy = accuracy / (batch_size * 2)\n",
    "            \n",
    "            if accuracy <= 0.8:\n",
    "                grads = tape.gradient(discriminator_loss, discriminator.trainable_weights)\n",
    "                disc_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370b5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
