{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea2ce7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 207 µs (started: 2023-03-09 11:59:48 +05:30)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2739ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.9.0\n",
      "\n",
      "tensorflow       : 2.10.0\n",
      "tensorflow_addons: 0.19.0\n",
      "pandas           : 1.5.3\n",
      "\n",
      "time: 3.68 s (started: 2023-03-09 11:59:48 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import wandb\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -p tensorflow,tensorflow_addons,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9b8ee1",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a818da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.26 ms (started: 2023-03-09 11:59:52 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class Conv2dBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters: int, kernel_size: int, strides: int, padding: str, name: str) -> None:\n",
    "        super(Conv2dBlock, self).__init__()\n",
    "        self.conv = keras.layers.Conv2D(\n",
    "            filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, name=f'{name}_conv'\n",
    "        )\n",
    "        self.bn = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.conv(x)\n",
    "        reshape = False\n",
    "        if len(x.shape) == 5:\n",
    "            shape = x.shape\n",
    "            reshape = True\n",
    "            x = tf.reshape(x, [shape[0], shape[1], shape[2], -1])\n",
    "            \n",
    "        if reshape:\n",
    "            x = tf.reshape(x, shape=shape)\n",
    "        x = self.bn(x)\n",
    "        x = keras.activations.relu(x)\n",
    "        return x\n",
    "    \n",
    "class Conv2dTransposeBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters: int, kernel_size: int, strides: int, padding: str, name: str) -> None:\n",
    "        super(Conv2dTransposeBlock, self).__init__()\n",
    "        self.conv = keras.layers.Conv2DTranspose(\n",
    "            filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, name=f'{name}_conv'\n",
    "        )\n",
    "        self.bn = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.conv(x)\n",
    "        reshape = False\n",
    "        if len(x.shape) == 5:\n",
    "            shape = x.shape\n",
    "            reshape = True\n",
    "            x = tf.reshape(x, [shape[0], shape[1], shape[2], -1])\n",
    "            \n",
    "        if reshape:\n",
    "            x = tf.reshape(x, shape=shape)\n",
    "        x = self.bn(x)\n",
    "        x = keras.activations.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97e5fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.29 ms (started: 2023-03-09 11:59:52 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class Conv3dBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters: int, kernel_size: int, strides: int, padding: str, name: str) -> None:\n",
    "        super(Conv3dBlock, self).__init__()\n",
    "        self.conv = keras.layers.Conv3D(\n",
    "            filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, name=f'{name}_conv'\n",
    "        )\n",
    "        self.bn = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.conv(x)\n",
    "        reshape = False\n",
    "        if len(x.shape) == 5:\n",
    "            shape = x.shape\n",
    "            reshape = True\n",
    "            x = tf.reshape(x, [shape[0], shape[1], shape[2], -1])\n",
    "        x = self.bn(x)\n",
    "        if reshape:\n",
    "            x = tf.reshape(x, shape=shape)\n",
    "        x = keras.activations.relu(x)\n",
    "        return x\n",
    "\n",
    "class Conv3dTransposeBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters: int, kernel_size: int, strides: int, padding: str, name: str) -> None:\n",
    "        super(Conv3dTransposeBlock, self).__init__()\n",
    "        self.conv = keras.layers.Conv3DTranspose(\n",
    "            filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, name=f'{name}_conv'\n",
    "        )\n",
    "        self.bn = keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.conv(x)\n",
    "        reshape = False\n",
    "        if len(x.shape) == 5:\n",
    "            shape = x.shape\n",
    "            reshape = True\n",
    "            x = tf.reshape(x, [shape[0], shape[1], shape[2], -1])\n",
    "        x = self.bn(x)\n",
    "        if reshape:\n",
    "            x = tf.reshape(x, shape=shape)\n",
    "        x = keras.activations.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1806c3",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e24a292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 918 µs (started: 2023-03-09 11:59:52 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class ImageEncoder(keras.Model):\n",
    "    def __init__(self, filters: List[int] = [64, 128, 256, 512, 400], \n",
    "                 kernel_sizes: List[int] = [11, 5, 5, 5, 8], \n",
    "                 strides: List[int] = [4, 2, 2, 2, 1], \n",
    "                 padding: List[str] = ['same', 'same', 'same', 'same', 'valid']) -> None:\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self._layers = []\n",
    "        \n",
    "        for ix in range(len(filters)):\n",
    "            self._layers.append(\n",
    "                Conv2dBlock(\n",
    "                    filters=filters[ix], kernel_size=kernel_sizes[ix], strides=strides[ix], \n",
    "                    padding=padding[ix], name=f'img_enc_conv2d_{ix}'\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        self.encoder = keras.Sequential(layers=self._layers, name='image_encoder')\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        latent = self.encoder(x, training)\n",
    "        mu, std = latent[..., :200], latent[..., 200:]\n",
    "        latent = mu + std * tf.random.normal(std.shape)\n",
    "        return latent, mu, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d86e47",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e229b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 743 µs (started: 2023-03-09 11:59:52 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class Generator(keras.Model):\n",
    "    def __init__(self, filters: List[int] = [512, 256, 128, 64, 1], \n",
    "                 kernel_sizes: List[int] = [4, 4, 4, 4, 4], \n",
    "                 padding: List[str] = ['valid', 'same', 'same', 'same', 'same'],\n",
    "                 strides: List[int] = [1, 2, 2, 2, 2]) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        for ix in range(len(filters)):\n",
    "            layers.append(\n",
    "                Conv3dTransposeBlock(filters=filters[ix], kernel_size=kernel_sizes[ix], \n",
    "                                           strides=strides[ix], padding=padding[ix], name=f'gen_conv3d_{ix}')\n",
    "            )\n",
    "        \n",
    "        self.gen = keras.Sequential(layers=layers, name='generator')\n",
    "    \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        return keras.activations.sigmoid(self.gen(tf.expand_dims(x, 1), training))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24beff8e",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f7e15b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 981 µs (started: 2023-03-09 11:59:52 +05:30)\n"
     ]
    }
   ],
   "source": [
    "class Discriminator(keras.Model):\n",
    "    def __init__(self, filters: List[int] = [64, 128, 256, 512, 1], \n",
    "                 kernel_sizes: List[int] = [4, 4, 4, 4, 4], \n",
    "                 padding: List[str] = ['same', 'same', 'same', 'same', 'valid'],\n",
    "                 strides: List[int] = [2, 2, 2, 2, 1]) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "        layers = []\n",
    "        for ix in range(len(filters)):\n",
    "            layers.append(\n",
    "                Conv3dBlock(\n",
    "                    filters=filters[ix], kernel_size=kernel_sizes[ix], strides=strides[ix], \n",
    "                    padding=padding[ix], name=f'disc_conv3d_{ix}'\n",
    "                )\n",
    "            )\n",
    "        self.disc = keras.Sequential(layers=layers, name='discriminator')\n",
    "        \n",
    "    def call(self, x: tf.Tensor, training: bool = True) -> tf.Tensor:\n",
    "        x = self.disc(x, training)\n",
    "        return keras.activations.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf1545",
   "metadata": {},
   "source": [
    "# Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c040ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Output shapes:-\n",
      "* x              : (32, 256, 256, 3)\n",
      "* latent         : (32, 1, 1, 200)\n",
      "* mu             : (32, 1, 1, 200)\n",
      "* std            : (32, 1, 1, 200)\n",
      "* reconstruction : (32, 64, 64, 64, 1)\n",
      "* disc_output    : (32, 1, 1, 1, 1)\n",
      "time: 9.87 s (started: 2023-03-09 11:59:52 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def run_test():\n",
    "    x = tf.random.normal((32, 256, 256, 3))\n",
    "    encoder = ImageEncoder()\n",
    "    decoder = Generator()\n",
    "    disc    = Discriminator()\n",
    "    \n",
    "    latent, mu, std = encoder(x)\n",
    "    reconstruction  = decoder(latent)\n",
    "    disc_output     = disc(reconstruction)\n",
    "    \n",
    "    print(f'''Output shapes:-\n",
    "* x              : {x.shape}\n",
    "* latent         : {latent.shape}\n",
    "* mu             : {mu.shape}\n",
    "* std            : {std.shape}\n",
    "* reconstruction : {reconstruction.shape}\n",
    "* disc_output    : {disc_output.shape}''')\n",
    "    \n",
    "run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c500c56c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a15d148b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 205 µs (started: 2023-03-09 12:00:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8aa9b",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Let $\\{x_i,y_i\\}$ be the training pairs, where $y_i$ is a 2D image and $x_i$ is the corresponding 3D shape. In each iteration $t$ of training, we first generate a random sample $z_t$ from $\\mathcal{N}(0, I)$. Then we update the discriminator $D$, the image encoder $E$, and the generator $G$ sequentially. Specifically, \n",
    "- __Step 1__: Update the disciminator $D$ by minimizing the following loss function: $$\\log(D(x_i)) + \\log(1 - D(G(z_t)))$$\n",
    "- __Step 2__: Update the image encoder $E$ by minimizing the following loss function: $$D_{KL}(\\mathcal{N}(E_{\\text{mean}}(y_i), E_{\\text{var}}(y_i))\\|\\mathcal{N(0, 1)})+\\|G(E(y_i)) - x_i\\|_2, $$ where $E_{\\text{mean}}(y_i)$ and $E_{\\text{var}}(y_i)$ are the predicted mean and variance of the latent variable $z$, respectively.\n",
    "- __Step 3__: Update the generator $G$ by minimizing the following loss function:\n",
    "$$\\log(1-D(G(z_t)))+\\|G(E(y_i)) - x_i\\|_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18015d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.22 ms (started: 2023-03-09 12:00:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "def run_training(num_epochs: int, train_ds: tf.data, valid_ds: tf.data, latent_dim: int = 200):\n",
    "    \n",
    "    encoder = ImageEncoder()\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "    \n",
    "    enc_optimizer = keras.optimizers.Adam(learning_rate=0.0025, beta_1=0.5, beta_2=0.5)\n",
    "    gen_optimizer = keras.optimizers.Adam(learning_rate=0.0025, beta_1=0.5, beta_2=0.5)\n",
    "    disc_optimizer = keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.5, beta_2=0.5)\n",
    "    \n",
    "    history = {\n",
    "        'encoder_loss': [],\n",
    "        'generator_loss': [],\n",
    "        'discriminator_loss': [],\n",
    "        'discriminator_accuracy': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        pbar = tqdm(enumerate(train_ds), total=len(train_ds), desc=f'EPOCH [{epoch+1}/{num_epochs}] (train) ')\n",
    "        for step, (y, x) in pbar:\n",
    "            '''\n",
    "            y - 2d image\n",
    "            x - 3d image\n",
    "            '''\n",
    "            batch_size = y.shape[0]\n",
    "            z = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "            print(f'y: {y.shape}\\nx: {x.shape}')\n",
    "            \n",
    "            # Gradient Descent on Image Encoder\n",
    "            with tf.GradientTape() as tape:\n",
    "                latent, mu, logvar = encoder(y)\n",
    "                reconstructed = generator(latent)\n",
    "                \n",
    "                encoder_loss = -0.5 * (1 + logvar - tf.square(mu) - tf.exp(logvar))\n",
    "                encoder_loss = tf.reduce_mean(tf.reduce_sum(encoder_loss, axis=1))\n",
    "                encoder_loss += tf.keras.losses.mse(y_pred=reconstructed, y_true=tf.expand_dims(x, -1))\n",
    "            grads = tape.gradient(encoder_loss, encoder.trainable_weights)\n",
    "            enc_optimizer.apply_gradients(zip(grads, encoder.trainable_weights))\n",
    "            \n",
    "            # Gradient Descent on Generator\n",
    "            with tf.GradientTape() as tape:\n",
    "                latent, mu, logvar = encoder(y)\n",
    "                reconstructed = generator(latent)\n",
    "                generator_loss = keras.losses.binary_crossentropy(y_true=tf.ones_like(reconstructed), y_pred=reconstructed)\n",
    "                generator_loss += keras.losses.mse(y_pred=reconstructed, y_true=tf.expand_dims(x, -1))\n",
    "            grads = tape.gradient(generator_loss, generator.trainable_weights)\n",
    "            gen_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "            \n",
    "            # Gradient Descent on Discriminator\n",
    "            with tf.GradientTape() as tape:\n",
    "                latent, mu, logvar = encoder(y)\n",
    "                reconstructed = generator(latent)\n",
    "                \n",
    "                disc_fake = discriminator(reconstructed)\n",
    "                disc_true = discriminator(tf.expand_dims(x, -1))\n",
    "                \n",
    "                discriminator_loss = keras.losses.binary_crossentropy(y_true=tf.ones_like(disc_true), y_pred=disc_true)\n",
    "                discriminator_loss += keras.losses.binary_crossentropy(y_true=tf.zeros_like(disc_fake), y_pred=disc_fake)\n",
    "            \n",
    "            accuracy = tf.reduce_sum(tf.cast(tf.cast((disc_fake > 0.5), dtype=tf.float32) == tf.zeros_like(disc_fake, dtype=tf.float32), dtype=tf.float32)) + \\\n",
    "            tf.reduce_sum(tf.cast(tf.cast((disc_true > 0.5), dtype=tf.float32) == tf.ones_like(disc_true, dtype=tf.float32), dtype=tf.float32))\n",
    "            accuracy = accuracy / (batch_size * 2)\n",
    "            \n",
    "            if accuracy <= 0.8:\n",
    "                grads = tape.gradient(discriminator_loss, discriminator.trainable_weights)\n",
    "                disc_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde4645a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<BatchDataset element_spec=TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None)>,\n",
       " <BatchDataset element_spec=TensorSpec(shape=(None, 64, 64, 64), dtype=tf.float32, name=None)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 337 ms (started: 2023-03-09 12:00:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "y = tf.data.Dataset.from_tensor_slices(tf.random.normal(shape=[512, 256, 256, 3])).batch(32)\n",
    "x = tf.data.Dataset.from_tensor_slices(tf.random.normal(shape=[512, 64, 64, 64])).batch(32)\n",
    "y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f99435ef-f08c-45a7-8485-ab29b9c1d647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 64, 64, 64), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.18 ms (started: 2023-03-09 12:00:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.zip(datasets=(y, x))\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec86ab3c-dcf4-43a3-b3be-d23998ffc46c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "      <th>voxels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0001.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0002.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0003.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0004.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0005.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_HEM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     pixels  \\\n",
       "0  ../../data/IKEA_imgs_shapes/bed/0001.png   \n",
       "1  ../../data/IKEA_imgs_shapes/bed/0002.png   \n",
       "2  ../../data/IKEA_imgs_shapes/bed/0003.png   \n",
       "3  ../../data/IKEA_imgs_shapes/bed/0004.png   \n",
       "4  ../../data/IKEA_imgs_shapes/bed/0005.png   \n",
       "\n",
       "                                              voxels  \n",
       "0  ../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...  \n",
       "1  ../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...  \n",
       "2  ../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...  \n",
       "3  ../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...  \n",
       "4  ../../data/IKEA_imgs_shapes/model/IKEA_bed_HEM...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.52 ms (started: 2023-03-09 12:00:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/IKEA_imgs_shapes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50254926-6c2f-494e-91bd-a81d7d00a81a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.43 ms (started: 2023-03-09 12:00:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08becbf3-30a6-4c07-be17-0e900d2326dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "      <th>voxels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0055.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0003.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0022.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0053.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_LIL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/IKEA_imgs_shapes/bed/0025.png</td>\n",
       "      <td>../../data/IKEA_imgs_shapes/model/IKEA_bed_HEM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     pixels  \\\n",
       "0  ../../data/IKEA_imgs_shapes/bed/0055.png   \n",
       "1  ../../data/IKEA_imgs_shapes/bed/0003.png   \n",
       "2  ../../data/IKEA_imgs_shapes/bed/0022.png   \n",
       "3  ../../data/IKEA_imgs_shapes/bed/0053.png   \n",
       "4  ../../data/IKEA_imgs_shapes/bed/0025.png   \n",
       "\n",
       "                                              voxels  \n",
       "0  ../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...  \n",
       "1  ../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...  \n",
       "2  ../../data/IKEA_imgs_shapes/model/IKEA_bed_MAL...  \n",
       "3  ../../data/IKEA_imgs_shapes/model/IKEA_bed_LIL...  \n",
       "4  ../../data/IKEA_imgs_shapes/model/IKEA_bed_HEM...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.02 ms (started: 2023-03-09 12:00:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e0fcac3-fa9b-4450-bddc-eb25c6b6c72c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 2), (10, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.77 ms (started: 2023-03-09 12:00:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "train_df = df.iloc[:50]\n",
    "valid_df = df.iloc[50:]\n",
    "\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e2c76fc-c770-40d9-85b5-0be9b11f80d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.87 ms (started: 2023-03-09 12:00:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "pixel_dataset = tf.data.Dataset.from_tensor_slices(df['pixels'].to_list())\n",
    "voxel_dataset = tf.data.Dataset.from_tensor_slices(df['voxels'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "700bbe2c-d024-4e2e-a495-4cfc2c5bb69c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 219 ms (started: 2023-03-09 12:00:03 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7724818-5669-4437-98a7-265440258845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.14 ms (started: 2023-03-09 12:00:03 +05:30)\n"
     ]
    }
   ],
   "source": [
    "pixel_dataset.take(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
